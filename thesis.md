Introduction
===

Automated theorem proving plays an important role in the modern program verification. Particularly in the context of verification with model checking techniques, an automated theorem prover is used to abstract an infinite set of program states into a finite one so that the model checker can virtually explore all possible program execution paths.

One of the most common methods of such abstraction is predicate abstraction. An automated theorem prover finds appropriate predicates for specific program locations. An execution state at each location is then expressed by a Boolean valuation of the given predicates. If the abstraction is too coarse and a model checker discovers an infeasible error execution path in an abstract system, the prover computes an additional predicate at a specific program location to refine the abstraction. The additional predicate must be satisfied at the location under the execution in the concrete model along the discovered path, and the execution does not lead to the program failure by the same path. After the refinement, the infeasible path is ruled out and no longer found by the model checker.

In order to obtain such a refinement predicate at the specific program location along the infeasible counterexample, one class of automated theorem provers, called an interpolating theorem prover, computes a Craig interpolant between two sets of constraints; the one consists of the constraints from the program entry point to the location, and the other consists of the constraints from the location to the program failure. Those constraints include variable assignments and assertions to be satisfied originated from conditional branches.

However, existing interpolating theorem provers may return too complex a solution which is heavily affected by the constraints of the specific path. This causes the model checker to discover infinitely similar paths which pass the same program location by loops or recursion calls, and not to terminate.

To avoid such situation, it is desired to use an invariant formula for the predicate abstraction. Based on the hypothesis that programâ€™s invariants tend to be simple formulas, we propose a new interpolating algorithm which tries to minimize the number of conjunctions and disjunctions in a solution. The predicate obtained by this algorithm may become similar to the invariant, and the number of trials in model checking may be reduced.

Additionally, we extend our interpolating algorithm to solve a symmetric interpolation problem, in which the algorithm computes predicates at multiple program locations along a path. This enables the abstraction predicates at multiple locations to be updated at the same computation.

Finally, we extend our algorithm to solve Horn clause solving problems. It allows us to obtain predicates which are highly likely to be program invariants, by computing the same abstraction predicates at loops and recursion calls on different passes, and by unifying predicates at the same location over multiple paths. The problems are generated by encoding constraints over execution paths with unknown predicates which describe functions' constraints between parameters and return values.

The rest of the paper is structured as follows. Chapter 2 proposes a new interpolating algorithm to obtain simple solutions, and extends it to solve symmetric interpolation problems. Chapter 3 describes a new Horn clause solving algorithm by extending the previous interpolating algorithm. Chapter 4 shows an experiment and its result to confirm the effect. Chapter 5 mentions related work and future work. As a conclusion, chapter 6 reviews the impact of our research.


Interpolation
===

Among various program verification techniques, when software model checking with predicate abstraction is adopted, the interpolation is used to compute the abstraction predicate along a spurious counterexample that a model checker discovered. It is done by computing a Craig's interpolant between the strongest postcondition at the location and the weakest precondition to the failure point at every program location.

Our algorithm focuses on interpolating problems on linear arithmetic.

Craig's Interpolation
---

Given two logical formulas A and B that are inconsistent each other, we call a new preposition I a Craig's interpolant between A and B such that $I$ is implied by $A$ and inconsistent with $B$. $I$'s vocabulary must be only free variables that appears in both $A$ and $B$.

Example
---

Consider the following interpolation problem.

A: (x \leq a) \wedge (a + 1 \leq y)
- - - - - -
B: (y \leq b) \wedge (b + 1 \leq x)

Here, the linear arithmetic formulas A and B are inconsistent. The interpolant I for this problem is (x-y+1 \leq 0), which is implied by A and inconsistent with B. The vocabulary of I is {x,y} and is over A's vocabulary {x,y,a} and B's {x,y,b}.

In computing the interpolant, we make a linear constraint of a interpolant by applying Farkas' lemma. First, we assing weight parameters to every expression in conjunction form.

\lambda_1 : -a+x     \leq 0
\lambda_2 :  a  -y+1 \leq 0
- - - - - -
\lambda_3 : -b  +y   \leq 0
\lambda_4 :  b-x  +1 \leq 0

Because all expressions induce inconsistent as a whole, the sum of weighted expressions should satisfy the following constraint.

- \lambda_1 + \lambda_2 = 0 (a)
- \lambda_3 + \lambda_4 = 0 (b)
  \lambda_1 - \lambda_4 = 0 (x)
- \lambda_2 + \lambda_3 = 0 (y)
  \lambda_2 + \lambda_4 > 0 (const)

With the linear constraint among \lambda_i above, the interpolant is represented as follows by the sum of weighted expressions from the first formula groups.

(- \lambda_1 + \lambda_2) a + \lambda_1 x - \lambda_2 y + \lambda_2 \leq 0

One of the model of the linear constraint is \lambda_i = 1 (1 \leq i \leq 4), and we obtain x-y+1 \leq 0 as a solution.

