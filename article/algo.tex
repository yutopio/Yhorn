\documentclass[a4paper,12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{syntax}

\newcommand{\sembrack}[1]{[\![#1]\!}
\newcommand{\edge}[2]{#1\rightarrow#2}
\newcommand{\edgel}[3]{#1\xrightarrow{#2}#3}

\title{Algorithm explanation}
\author{Yuto Takei \\ The University of Tokyo}

\begin{document}


\section{Horn clause solving}

We propose a new algorithm for solving recursion-less Horn clauses to
generate a solution which is as simple as possible.  This enables us
to obtain appropriate predicates that are suitable for predicate
abstraction in the program verification techniques.

The construction of the algorithm roughly consists of two parts.
\begin{itemize}
\item \textbf{Iterative Constraint Generation} is a process to build a
  constraint to compute a solution.  It starts from generating the
  weakest constraint in the sense that the resulting solution would
  not be simple yet.  The process iteratively strengthen a constraint
  until the strongest one while preserving the constraint
  satisfiability.  The strongest constraint gives a simple solution.
\item \textbf{Problem Restructuring} If the constraint become
  unsatisfiable during the iteration, the process restructure the
  problem equivalent to obtain a less simpler solution.  This process
  considers the unsatisfiable core of the constraint.
\end{itemize}

All predicate variables in an input problem are assigned simple
templates.  Those predicate templates are parameterized.  In the
iterative constraint generation process, algorithm builds a linear
constraint that parameters in templates must satisfy.  This is done in
a constructive manner, and constraints are build in the order of
implication dependency in Horn clauses.  That is, when an input
problem has a Horn clause thath has a predicate variable $P$ on its
left-hand and $Q$ on its right-hand, a constraint to describe
parameters in $P$'s template are first build before those in $Q$'s
template.  When all parameters in the whole problem are described, the
built constraint are evaluated to obtain a model.  Its instanciation
becomes an appropriate solution for the input problem.

The novelty of our algorithm lies in the incremental constraint
refinement.  The algorithm try from the weakest constraint that an
input problem allows that does not give a simple solution, and
strengthen the constraint until it reaches to the simplest solution
that the problem has.  When a constraint becomes unsatisfiable, the
algorithm analyzes the unsatisfiable core and transform the problem to
obtain less simple solution.

This construction of the algorithm enables us to compute a relatively
simpler solution compared to existing algorithms in a reasonable time.

\subsection{Example}

\paragraph {Tree interpolation}
First, consider the following example.

\begin{align*}
x \leq 1 & \implies A(x) \\
y \leq 2 & \implies B(y) \\
A(x) \wedge B(y) & \implies 3x+2y \leq 10
\end{align*}

In this example, we would like to compute linear arithmetic formulas
for the predicate variables $A$ and $B$.  They appear only once on
both left-hand and right-hand globally in the problem.

We try to obtain a simple solution that is expressed by linear
expression templates, whose coefficients and constants are
parameterized.  Assume that they have following predicate templates.

\begin{align*}
A(x) : c_1 x + c_2 \leq 0 \\
B(y) : c_3 y + c_4 \leq 0
\end{align*}

By naturally encoding the first Horn clause with Farkas's lemma, we
obtain a linear constraint
$ \lambda_1 = c_1 \wedge - \lambda_1 \geq c_2 \wedge \lambda_1 \geq 0 $.
Any assignment to $ c_1, c_2, \lambda_1 $ which satisfies this will
make $A(x)$ valid for the first clause.  In the same manner, we obtain
$ \lambda_2 = c_3 \wedge - 2 \lambda_2 \geq c_4 \wedge \lambda_2 \geq 0 $
from the second clause, and
$ c_1 = 3 \lambda_3 \wedge c_3 = 2 \lambda_3 \wedge c_2 + c_4 \geq -10 \lambda_3 \wedge \lambda_3 > 0 $
from the third.

One of the models satisfying all the constraints above is
$( c_1, c_2, c_3, c_4, \lambda_1, \lambda_2, \lambda_3 ) = (3, -3, 2, -4, 3, 2, 1)$.
By assigning them to the template, we obtain the following solution.

\begin{align*}
A(x) : 3 x - 3 \leq 0 \\
B(y) : 2 y - 4 \leq 0
\end{align*}

\paragraph {DAG problem solving}
Second, we explain a case that some predicate variables appear
multiple times on left-hand side in different Horn clauses.

\begin{align*}
x \leq 1 & \implies A(x) \\
A(x) \wedge A(y) & \implies x+y \leq 2
\end{align*}

Assigning a template $A(x) : c_1 x + c_2 \leq 0$, we obtain the same
constraint for the first clause as the previous example.

\begin{align} \label{eq:constr1}
\lambda_1 = c_1 \wedge - \lambda_1 \geq c_2 \wedge \lambda_1 \geq 0
\end{align}

Sinve we have $A$'s appearance twice on the second clause, it is
possible for $A$ to have two expressions each of which is used for
$A(x)$ and $A(y)$.  Although we need to use the same template for
multiple occurrences in order to compute the simplest solution, it may
make the whole constraints unsatisfiable if the simplest solution does
not exist.

Therefore, we generate a weaker constraint for the second clause that
allows different expressions of $A$ for multiple occurrence.  If the
whole constraint is satisfiable in the case, we try to solve in a
stronger constraint to generate a simple solution.

In this specific case, it is virtually equivalent to solve the
following problem in a weaker constraint.

\begin{align*}
\text{Problem:} \\
x \leq 1 & \implies A_1(x) \\
x \leq 1 & \implies A_2(x) \\
A_1(x) \wedge A_2(y) & \implies x+y \leq 2 \\
\\
\text{Templates:} \\
A_1(x) \text{ : } & c_{1,1} x + c_{2,1} \leq 0 \\
A_2(x) \text{ : } & c_{1,2} x + c_{2,2} \leq 0 \\
A(x) \text{ : } & A_1(x) \wedge A_2(x) \\
\end{align*}

By duplicating the constraint~\ref{eq:constr1} of $A$ for newly
created $A_1$ and $A_2$, we obtain the whole constraint as follows.

\begin{align*}
& \lambda_{1,1} = c_{1,1} \wedge - \lambda_{1,1} \geq c_{2,1} \wedge \lambda_{1,1} \geq 0 \wedge \\
& \lambda_{1,2} = c_{1,2} \wedge - \lambda_{1,2} \geq c_{2,2} \wedge \lambda_{1,2} \geq 0 \wedge \\
& c_{1,1} = \lambda_2 \wedge c_{1,2} = \lambda_2 \wedge c_{2,1} + c_{2,2} \geq 2 \lambda_2 \wedge \lambda_2 > 0
\end{align*}

This constraint is satisfiable and one model is
\[ ( c_{1,1}, c_{1,2}, c_{2,1}, c_{2,2}, \lambda_{1,1}, \lambda_{1,2}, \lambda_2 ) =
( 1, -1, 1, -1, 1, 1, 1 ) \] and the solution then becomes
$A(x) : (x -1 \leq 0) \wedge (x -1 \leq 0)$.

Since the weak constraint is satisfiable, we now refine the constraint
to obtain the better solution.  That is, simply eliminate the
duplication to build the following constraint for the original
template.

\begin{align*}
& \lambda_1 = c_1 \wedge - \lambda_1 \geq c_2 \wedge \lambda_1 \geq 0 \wedge \\
& c_1 = \lambda_2 \wedge c_1 = \lambda_2 \wedge 2 c_2 \geq 2 \lambda_2 \wedge \lambda_2 > 0
\end{align*}

Solving this constraint simply gives us a solution $A(x) : x -1 \leq 0$.

\paragraph {Disjunctive Horn clause solving}
Finally, we explain a case that an input set of Horn clauses contain
disjunctions on left-hand side.

\begin{align*}
x \leq 0 \wedge -x \leq 0 & \implies A(x) \\
x+1 \leq 0 \vee -x+1 \leq 0 & \implies B(x) \\
A(x) \wedge B(x) & \implies 1 \leq 0
\end{align*}

Same as the previous examples, templates for predicate variables are
prepared.

\begin{align*}
A(x) : c_1 x + c_2 \leq 0 \\ B(x) : c_3 x + c_4 \leq 0
\end{align*}

The constraints generated are follows.

\begin{align*}
& \lambda_1 - \lambda_2 = c_1 \wedge 0 \geq c_2 \wedge \lambda_1 \geq 0 \wedge \lambda_2 \geq 0 \wedge \\
& \lambda_3 = c_3 \wedge \lambda_3 \geq c_4 \wedge \lambda_3 \geq 0 \wedge \\
& - \lambda_4 = c_3 \wedge \lambda_4 \geq c_4 \wedge \lambda_4 \geq 0 \wedge \\
& c_1 + c_3 = 0 \wedge c_2 + c_4 > 0
\end{align*}

The constraints here become unsatisfiable, and one possible
unsatisfiable core is:

\begin{align*}
\lambda_3 & = c_3 \\
\lambda_3 & \geq c_4 \\
- \lambda_4 & = c_3 \\
\lambda_4 & \geq c_4 \\
c_2 + c_4 & > 0 \\
0 & \geq c_2
\end{align*}

Because the unsatisfiable core contains constraints originating from
the disjunctions to be expressed in a single term template.  This let
us determine to relax the template to allow a enlarged solution.

Now we slightly change the problem and the template.

\begin{align*}
\text{Problem:} \\
x \leq 0 \wedge -x \leq 0 & \implies A(x) \\
x+1 \leq 0 & \implies B_1(x) \\
-x+1 \leq 0 & \implies B_2(x) \\
A(x) \wedge B_1(x) & \implies 1 \leq 0 \\
A(x) \wedge B_2(x) & \implies 1 \leq 0 \\
\\
\text{Templates:} \\
A(x) \text{ : } & c_1 x + c_2 \leq 0 \\
B_i(x) \text{ : } & c_{3,i} x + c_{4,i} \leq 0 \quad (i \in \left\lbrace 1,2 \right\rbrace ) \\
B(x) \text{ : } & B_1(x) \vee B_2(x)
\end{align*}

When we construct the constraints, as same as previous, we again
obtain an unsatisfiable core:

\begin{align*}
\text{Constraint:} \\
TODO \\
\\
\text{Unsatisfiable core:} \\
TODO
\end{align*}

This time, the unsatisfiable core contains the constraints that
originate from

TODO

\begin{align*}
\text{Problem:} \\
x \leq 0 \wedge -x \leq 0 & \implies A_i(x) \quad (i \in \left\lbrace 1,2 \right\rbrace ) \\
x+1 \leq 0 & \implies B_1(x) \\
-x+1 \leq 0 & \implies B_2(x) \\
A_i(x) \wedge B_j(x) & \implies 1 \leq 0 \quad (i,j \in \left\lbrace 1,2 \right\rbrace ) \\
\\
\text{Templates:} \\
A_i(x) \text{ : } & c_{1,i} x + c_{2,i} \leq 0 \quad (i \in \left\lbrace 1,2 \right\rbrace ) \\
A(x) \text{ : } & A_1(x) \wedge A_2(x) \\
B_i(x) \text{ : } & c_{3,i} x + c_{4,i} \leq 0 \quad (i \in \left\lbrace 1,2 \right\rbrace ) \\
B(x) \text{ : } & B_1(x) \vee B_2(x)
\end{align*}

Finally, we obtain the following constraint:

TODO


The process also generates a predicate template for every predicate
variable that the solution will become.  under certain solution
template.

\subsection{Preliminaries}

For ease of discussion, our algorithm handles an input set of Horn
clauses by a \emph{Horn graph} that express the equivalent problem.
The graph is then used throughout the algorithm to represent the
problem.  A Horn graph is a labelled directed acyclic graph
$G=(V,E,\varphi)$.
\begin{itemize}
\item $V$ is a union of two disjoint sets of vertices; Horn term
  vertices $V_T$ and arrow vertices $V_\Rightarrow$.  Each vertex $u
  \in V_\Rightarrow$ has eactly one outgoing edge to some $v \in V_T$,
  denoted as $succ(u)$.
\item $E$ is a set of labelled edges, which are expressed in the form
  $(u,v,\theta)$ where $\theta$ is a finite map from variables to
  variables.
\item $\varphi: V_T \rightarrow L$ is a labelling function for Horn
  term vertices, where L is a set of elements of a predicate variable
  in the form $P(x_1, \ldots, x_{\mathrm{arity}(P)})$ or a linear
  inequality $a_1 x_1 + \cdots + a_n x_n + b \leq 0$.
\end{itemize}
There are two kinds of edges in a Horn graph;
\begin{itemize}
\item for $u \in V_T, v \in V_\Rightarrow$, an edge takes a form
  $(u,v,\theta)$, written $\edgel{u}{\theta}{v}$, or,
\item for $u \in V_\Rightarrow, v \in V_T$, an edge takes a form
  $(u,v,\emptyset)$, written $\edge{u}{v}$, where the mapping is
  empty.
\end{itemize}
The meaning $\llbracket G \rrbracket $ of a Horn graph $G$ is a set of
Horn clauses $\mathcal{HC}_v$ for all vertices $v \in V_\Rightarrow$.
\begin{align*}
\mathcal{HC}_v & = \left( \bigwedge_{(u,v,\theta) \in E} \theta \varphi(u) \right) \Longrightarrow \varphi(succ(v)) \\
\llbracket G \rrbracket & = \bigwedge_{v \in V_\Rightarrow} \mathcal{HC}_v
\end{align*}
We implicitly assume each $\mathcal{HC}_v$ is universally quantified
by its all free variables $\textsc{FV}(\mathcal{HC}_v)$.

Horn term vertices with predicate variable labels are unique each
other that any of them do not have the same variable on their labels.
From now on, we may denote a Horn term vertex with a predicate
variable label by its predicate variable name if no ambiguity is
present.

Without loss of generality, we assume the existence of the \emph{root
  vertex} $v_\bot \in V_T$ with linear expression labels $1 \leq 0$,
meaning $\bot$.  This is because if we have a Horn clause $P \implies
e$ which $e$ is a linear expression, we can convert it to $P \wedge
\neg e \implies 1 \leq 0$.  We also assume that other vertices with
linear expression labels have no incoming edges to them.

For simplicity of discussion, we define \emph{term arity} $k_v$ for
every Horn term vertex $v \in V_T$ with incoming edges.
\begin{align*}
k_v =
\begin{cases}
\mathrm{arity}(P) & \mbox{if } \varphi(v) = P(x_1,...,x_{\mathrm{arity}(P)}) \\
0 & \mbox{if } \varphi(v) = \bot
\end{cases}
\end{align*}
We let $K$ denote the maximum of $k_v$ over all $v \in V_T$.

A variable mapping label $\theta$ on edges is used to map the index of
one predicate variable to another. (TODO?)

(Example?)

The algorithm assigns a \emph{predicate template} for all predicate
variables in $G$. A template for a predicate variable $P(x_1, \ldots, x_n)$
is a formula $\psi$ constructed from the following definition.
\begin{align*}
\psi ::= & a_1 x_1 + \cdots + a_n x_n + b \leq 0 \mid \\
& \psi \wedge \psi \mid \psi \vee \psi
\end{align*}
A linear expression in the definition above may also be represented in
a equivalent vector form $\mathbf{a} \mathbf{x} + b \leq 0$ for short.
Parameters $\mathbf{a}$ and $b$ are specified by a linear constraint.

The solution of $G$ is a map $\rho$ from predicate variables to linear
predicates of the form $\lambda x_1, \ldots ,x_n. \psi$ where
parameters in $\psi$ are replaced with constant and $\rho[G]$ becomes
a tautology.  A solution is \textit{simple} if $\rho[P]$ is of the
form $\mathbf{a} \mathbf{x} + b \leq 0$ for every $P$ in
$\mathrm{dom}(\rho)$.

The problem of solving Horn clauses (represented by $G$) is to find a
solution of $G$ (and a simple solution if possible).

\subsection{Simple solution}

We first propose an algorithm to compute a simple solution for the
given Horn graph $G$ if one exists.  Later we add modifications to the
algorithm for the case that a simple solution does not exist for $G$.
In such a case, we transform the input graph $G$ to have a larger
solution template.

We define the relation $\leadsto$ over $V_T$ as follows.
\[ u \mathop{\leadsto}^\theta v \Longleftrightarrow
\exists a \in V_\Rightarrow; \edgel{v}{\theta}{a} \wedge \edge{a}{v} \]
We may omit $\theta$ and write $u \leadsto v$ for convenience in later
discussions. By the assumption that $G$ is acyclic, $\leadsto^+$ is a
well-founded relation. $v_\bot$ is the greatest element with respect
to $\leadsto^+$.

For each Horn term vertex $v \in V_T$, we define
$\Delta(v) = (\mathbf{a}_v \mathbf{x}_v \leq b_v, C_v)$
, where
\begin{itemize}
\item $\mathbf{a}_v \mathbf{x}_v \leq b_v$ is a linear inequality that
  contains coefficient variables $\mathbf{a}_v$ and a constant $b_v$,
  and
\item $C_v$ is a set of linear expressions on coefficient variables.
\end{itemize}
Intuitively, it denotes the set of inequalities:
\begin{align*}
\left\lbrace
 \mathbf{a}_v \mathbf{x}_v + b_v \leq 0 \middle|
 \exists \left( \textsc{FV}(C_v)
  \setminus (\mathbf{a}_v \cup \left\lbrace b_v \right\rbrace
 \right); C_v
\right\rbrace
\end{align*}
For a predicate variable vertex, $\mathbf{a}_v \mathbf{x}_v + b_v \leq
0$ serves as a predicate template and $C_v$ describes the parameters
$\mathbf{a}_v$ and $b_v$.

$C_v$ is defined by well-founded induction on $v$ with respect to the
relation $\leadsto^+$. Then, $C_v$ can be shown as follows.

\begin{align*}
\hat C_{a,v} = &
 \bigcup_{\edgel{u}{\theta}{a}} C_u \cup
 \bigcup_{0 < i \leq K}
 \left\lbrace
  \mathbf{a}_{v,i} = \sum_{\edgel{u}{\theta}{a}} \mathbf{a}_{u, \theta^{-1} (i)}
 \right\rbrace \\
 & \hspace{2cm} \cup
 \left\lbrace
  b_v \geq \sum_{\edgel{u}{\theta}{a}} b_u
 \right\rbrace \cup
 \bigcup_{k_v < i \leq K}
 \left\lbrace \mathbf{a}_{v,i} = 0 \right\rbrace
\\
C_v = & \bigcup_{\edge{a}{v}} \hat C_{a,v} \cup
\begin{cases}
\emptyset
& \mbox{if } \varphi(v) = P(\mathbf{x}_v) \\
\left\lbrace
 \lambda_v \geq 0, \mathbf{a}_v = \lambda_v \mathbf{a}_0,
 b_v = \lambda_v b_0
\right\rbrace
& \mbox{if } \varphi(v) = \mathbf{a}_0 \mathbf{x}_v \leq b_0
\end{cases} \\
\end{align*}
For simplicity, we assume variables $\mathbf{a}_u$, $b_u$ are obtained
from $C_u$.

Any model $\sigma$ to the constraint $C_{v_\bot}$ gives a simple
solution for $G$ if $C_{v_\bot}$ is satisfiable, i.e., we should have:

\begin{quote}
If $\models \sigma(C_{v_\bot})$, then $\rho$ defined by
\begin{align*}
 \rho = \left\lbrace
  \left( P, \sigma(\mathbf{a}_v \mathbf{x}_v \leq b_v) \right) \middle|
  \forall v \in V_T; \varphi(v) = P(\mathbf{x}_v)
 \right\rbrace
\end{align*}
is a solution of $G$.
\end{quote}

If $C_{v_\bot}$ is unsatisfiable, no simple solution exists for $G$.
There are two cases that a simple solution does not exist for a
predicate variable.
\begin{itemize}
\item A predicate variable appears multiple times on left-hand of Horn
  clauses, and those appearances require different expressions as an
  assumption.
\item A predicate variable is implied by a disjunctive Horn clause,
  which has disjunctions on its left-hand, and a common premise that
  the disjunctions induce is not strong enough for solving a problem.
\end{itemize}

The first case occurs in a case like follows.
\begin{align*}
% conj.txt ... originated from uc/01.txt
\left( x \leq 0 \right) \wedge \left( y \leq 0 \right) & \implies P(x,y) \\
P(x,a) \wedge P(b,y) & \implies x+y \leq 0
\end{align*}
In this example, the predicate variable $P$ appears twice on the
second clause and they require different premises; $x \leq 0$ for the
first and $y \leq 0$ for the second.  They cannot be represented by
$\mathbf{ax} + b \leq 0$ template at the same time.

The second case occurs in a case like follows.
\begin{align*}
% disj-simp.txt ... originated from 23simp_neg.txt
\left( x+1 \leq 0 \right) \vee \left( -x+1 \leq 0 \right) & \implies P(x) \\
P(x,y) \wedge \left( x \leq 0 \right) \wedge \left( -x \leq 0 \right) & \implies \bot
\end{align*}
In this example, the predicate variable $P$ is implied by the first
clause, which is a disjunctive Horn clause.  As a simple solution, $P$
can take a common consequence that both of $x+1 \leq 0$ and $-x+1 \leq
0$ induce.  However, such a simple linear expression does not exist
except for $0 \leq 0$, which is equivalent to $\top$, and it is not
sufficient to satisfy the second clause.

Both cases can be fixed by enlarging the solution template.


\subsection {Graph transformation}

If a simple solution does not exist for $G$, we try to give a less
simpler solution by transforming $G$ and relaxing the constraint
$C_{v_\bot}$.  This transformation takes place by considering the
unsatisfiable core from the constraint.  Depending on the reason for
the absence of a simple solution, the way of the transformation
differs.

Algorithm~\ref{alg:solveHorn} shows the updated pseudo-code of our
Horn clause solving algorithm with the graph transformation.  It takes
an input Horn graph and returns a mapping between predicate variables
and linear arithmetic formulas.

\newcommand{\solveHorn}{\ensuremath{\mbox{\sc SolveHornGraph}}}
\newcommand{\genConstr}{\ensuremath{\mbox{\sc GenerateConstraint}}}
\newcommand{\transGraph}{\ensuremath{\mbox{\sc TransformGraph}}}

\begin{algorithm}
\caption{$ \solveHorn (G) $}\label{alg:solveHorn}
\begin{algorithmic}
\STATE {$v_\bot \gets $ the root node of $G$}
\STATE {$V_\star \gets \left\lbrace v_\bot \right\rbrace$}
\REPEAT
  \STATE {$C_{v_\bot} \gets \genConstr (G, v_\bot, V_\star)$}
  \IF {$C_{v_\bot}$ is satisfiable}
    \STATE {$\sigma \gets $ one model of $C_{v_\bot}$}
    \STATE {$V_\star \gets V_\star \cup \left\lbrace u \in V_T \mid \forall v \in V_\star; u \leadsto v \right\rbrace$}
  \ELSE
    \STATE {$U \gets $ unsatisfiable core for $C_{v_\bot}$}
    \STATE {$G \gets \transGraph (G, U)$}
    \STATE {$V_\star \gets \left\lbrace v_\bot \right\rbrace$}
  \ENDIF
\UNTIL {$V_\star = V_T$}
% TODO: Consider predicate templates?
\STATE {Build solution by $\sigma$}
\end{algorithmic}
\end{algorithm}
\transGraph procedure determines the unsatisfiable core of the
constraint and transform the Horn graph $G$ and predicate templates.
As mentioned earlier, two ways of graph transformation exist.

\paragraph{Conjunction split}

\paragraph{Disjunction split}

The constraints are first built the weakest so that the disjunctiveness of
whole solution template is fixed first.  The strength matters that the
predicate variables are used as the same expressions depending on
different appearances of the predicate variable.

The strngeth of the constraint is controlled by a set of vertices $V$
in the pseudo-code.  Predicate variable vertices in $V$ are treated
strictly unique across the different appearances of the predicate
variables in Horn clauses.



$\genConstr$ procedure produces the constraint for a given vertex $v$.


\begin{algorithm}
\caption{$ \genConstr (G, v, visited) $}\label{alg:genConstr}
\begin{algorithmic}
\STATE {$C \gets \emptyset$}
\FORALL {$v_\Rightarrow \in preds_G(v)$}
  \FORALL {$v_p \in preds_G(v_\Rightarrow)$}
    \IF {$\varphi (v_p)$ is a predicate variable}
      \STATE {$C \gets C \cup \genConstr (G, v_p, visited)$}
    \ELSE
      \STATE { $id$ }
    \ENDIF
  \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}





traverses the input graph in the topological order on
$V_\Rightarrow$, and concatenate the constraints from predecessors to
build the problem constraints.  Each process to build a constraint on
$\mathcal{HC}_v$ for all vertices $v \in V_\Rightarrow$ is equivalent
to generate a linear constraint in interpolation.










\subsection{Refinement from Unsatisfiable Core}

An unsatisfiable core $\mathcal{U}$ is a subset of $C_{v_\bot}$.
If a vertex $v \in V$ with the copy origin $U$ satisfies:
\begin{align*}
& \exists t, u \in V; v \leadsto t \wedge v \leadsto u \wedge \\
& \left( \exists i, j, k;
\left\lbrace \left( \mathbf{a}_{s,U,j} = \ldots + \mathbf{a}_{v,U,i} + \ldots \right),
\left( \mathbf{a}_{t,U,k} = \ldots + \mathbf{a}_{v,U,i} + \ldots \right)
\right\rbrace \subseteq \mathcal{U} \right)
\end{align*}
we add $v$ to the copy tree $T$.




\bibliographystyle{plain}
\bibliography{./biblio}

\end{document}
